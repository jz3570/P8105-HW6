---
title: "P8105"
author: "Jiawen Zhao"
date: "11/25/2022"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggridges)
library(patchwork)
library(gridExtra)
library(modelr)
```

#### Problem 2

```{r}
homicide <- read.csv("./data/homicide-data.csv")%>% 
  na.omit() %>% 
  unite(city_state, c(city,state),sep = ", ") %>% 
  mutate(solved = case_when(grepl("Closed by arrest", disposition)==TRUE ~ 1,
  grepl("Closed by arrest", disposition)==FALSE ~ 0)) %>% 
  mutate(unsolved = case_when(grepl("Closed by arrest", disposition)==FALSE ~ 1,
  grepl("Closed by arrest", disposition)==TRUE ~ 0)) %>% 
  filter(!str_detect(city_state, "Dallas, TX"))%>% 
  filter(!str_detect(city_state, "Phoenix, AZ"))%>% 
  filter(!str_detect(city_state, "Kansas City, MO"))%>% 
  filter(!str_detect(city_state, "Tulsa, AL"))%>% 
  filter(str_detect(victim_race, c("White", "Black"))) %>% 
  mutate(victim_age =as.numeric(victim_age))%>% 
  na.omit()
BMD = filter(homicide,city_state=="Baltimore, MD")
fit_logistic = BMD%>% 
  glm(solved ~ victim_age + victim_race + victim_sex, data = ., family = binomial())
fit_logistic %>% 
  broom::tidy(conf.int = TRUE) %>% 
  mutate(OR = exp(estimate), adj.conf.low=exp(conf.low), adj.conf.high=exp(conf.high)) %>%
  select(term, log_OR = estimate, OR, p.value, adj.conf.low, adj.conf.high, conf.low, conf.high) %>% 
  knitr::kable(digits = 3)
exp(summary(fit_logistic)$coefficients["victim_sexMale",1] + qnorm(c(0.025,0.5,0.975)) * summary(fit_logistic)$coefficients["victim_sexMale",2])
```

Keeping all other variables fixed, the estimate of the adjusted odds ratio for solving homicides comparing male victims to female victims is 0.4687305, with confidence interval of (0.3193133, 0.6880650).

```{r}
city_fit_glm = 
  homicide %>%
  nest(data = -city_state) %>% 
  mutate(model = map(data, ~glm(solved~victim_age + victim_race + victim_sex, data = ., family = binomial())),
         result = map(.x=model, ~broom::tidy(.x,conf.int = TRUE))) %>% 
  select(city_state,result)%>% 
  unnest(result)%>% 
  mutate(OR = exp(estimate), adj.conf.low=exp(conf.low), adj.conf.high=exp(conf.high)) %>%
  select(city_state,term, log_OR = estimate, OR, p.value, adj.conf.low, adj.conf.high) %>% 
  filter(term == "victim_sexMale")

```

````{r}
city_fit_glm%>%
  mutate(
    city_state = fct_reorder(city_state, -OR)
  ) %>%
  ggplot(aes(x = OR, y = city_state)) +
  geom_point() +
  geom_errorbar(aes(xmin = adj.conf.low, xmax = adj.conf.high)) +
  ylab("City, state") +
  xlab("Odds ratio") +
  labs(title = "Adjusted odds ratio of solved cases for male and female victims")

```

Based on the plot, we can see that Long Beach CA has the lowest estimated OR for male and female victims, which means the case solve rate is not too different between males and females, and Stockton, CA has the highest OR for male and female victims, which means the case solve rate is very different between males and females. Also, we see that for most of the cities, the distribution of estimated OR is right skewed.


# Problem 3

```{r}
birthweight <- read.csv("./data/birthweight.csv")%>% 
  na.omit() %>% 
  mutate(babysex = as.factor(babysex)) %>% 
  mutate(frace = as.factor(frace))%>% 
  mutate(mrace = as.factor(mrace))%>% 
  mutate(malform = as.factor(malform))
  
birthweight %>% 
  ggplot(aes(x = bhead, y = bwt)) + 
  geom_point(alpha = .5)+
  ylab("Baby weight at birth") +
  xlab("Baby head circumference at birth") +
  labs(title = "plot of baby weight vs baby head circumference at birth")

birthweight %>% 
  ggplot(aes(x = blength, y = bwt)) + 
  geom_point(alpha = .5)+
  ylab("Baby weight at birth") +
  xlab("Baby length at birth") +
  labs(title = "plot of baby weight vs baby length at birth")

fit1 = lm(bwt ~ bhead+blength, data = birthweight)
summary(fit1)
summary(fit1)$coef
coef(fit1)
#fitted.values(fit1)
fit1 %>% 
  broom::glance()%>% 
  broom::tidy()

birthweight %>% 
  modelr::add_residuals(fit1) %>% 
  modelr::add_predictions(fit1) %>%
  ggplot(aes(x = pred, y = resid)) + geom_point()+
  ylab("Residual") +
  xlab("Fitted value") +
  labs(title = "plot of residual vs fit for model 1")

#plot(fit1)
```


Firstly, from common sense I choose baby’s head circumference at birth and baby’s length at birth to be the predictors in my model. The information form internet consist with my hypothesis, where I found that the baby weight at birth could be related to baby's head circumference since most weight of a baby is at their head part. Also, I found that longer baby could weight more, just like adults where a taller person could probably weight more compared to a shorter person. After selecting those two potential predictors, I created two scatter plot to investigate the relationship between those two variables and baby weight as birth. From the first scatter plot, we see that there's possible a linear relationship between baby weight and baby head circumference at birth. From the second plot, we also see that there's possible a linear relationship between baby weight and baby length at birth. From those plot, and common sense, I decide to build my model with baby’s head circumference at birth and baby’s length at birth as the predictors to predict baby's weight at birth.


From the residual vs fit plot, we see that the points are randomly spread around zero. Although there's some pattern in the left part, most part of the plot shows no specific pattern. 

```{r}
fit2 = lm(bwt ~ blength + gaweeks, data = birthweight)
summary(fit2)
summary(fit2)$coef
coef(fit2)
#fitted.values(fit2)
fit2 %>% 
  broom::glance()%>% 
  broom::tidy()

birthweight %>% 
  modelr::add_residuals(fit2) %>% 
  modelr::add_predictions(fit2) %>%
  ggplot(aes(x = pred, y = resid)) + geom_point()+
  ylab("Residual") +
  xlab("Fitted value") +
  labs(title = "plot of residual vs fit for model 2")

```

From the residual vs fit plot, we see that the points are randomly spread around zero. Although there's one outlier in the left part, most part of the plot shows no specific pattern. 

```{r}
fit3 = glm(bwt ~ bhead + blength + babysex + bhead*blength*babysex, data = birthweight)
summary(fit3)
summary(fit3)$coef
coef(fit3)
#fitted.values(fit3)
fit3 %>% 
  broom::glance()%>% 
  broom::tidy()

birthweight %>% 
  modelr::add_residuals(fit3) %>% 
  modelr::add_predictions(fit3) %>%
  ggplot(aes(x = pred, y = resid)) + geom_point()+
  ylab("Residual") +
  xlab("Fitted value") +
  labs(title = "plot of residual vs fit for model 3")

```

From the residual vs fit plot, we see that the points are randomly spread around zero. Although there're some outliers in the left part, they are not very far from the majority of the points and most part of the plot shows no specific pattern. 

```{r}
cv_df =
  crossv_mc(birthweight, 100) %>% ##always use 100??????
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
# cv_df %>% pull(train) %>% .[[1]] %>% as_tibble
# cv_df %>% pull(test) %>% .[[1]] %>% as_tibble
cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

```{r}
cv_df = 
  cv_df %>% 
  mutate(
    fit1  = map(train, ~lm(bwt ~ blength + bhead, data = .x)),
    fit2  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    fit3  = map(train, ~glm(bwt ~ bhead + blength + babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(
    rmse_fit1 = map2_dbl(fit1, test, ~rmse(model = .x, data = .y)),
    rmse_fit2 = map2_dbl(fit2, test, ~rmse(model = .x, data = .y)),
    rmse_fit3 = map2_dbl(fit3, test, ~rmse(model = .x, data = .y)))

```


```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()

```


We can see that the last model, general linear model, and the first model are better than the second model, since they have smaller rmse, compared to the second model. The second model is the worst, and that shows the importance of choosing the right predictors to put into the mode. Although the second model and the first model both have two predictors and the third model has more predictors, the first and the third model have similar performance and the second model is the worst one

